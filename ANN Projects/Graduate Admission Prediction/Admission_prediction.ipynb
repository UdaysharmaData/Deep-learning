{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Admission_Predict_Ver1.1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Serial No.         500 non-null    int64  \n",
      " 1   GRE Score          500 non-null    int64  \n",
      " 2   TOEFL Score        500 non-null    int64  \n",
      " 3   University Rating  500 non-null    int64  \n",
      " 4   SOP                500 non-null    float64\n",
      " 5   LOR                500 non-null    float64\n",
      " 6   CGPA               500 non-null    float64\n",
      " 7   Research           500 non-null    int64  \n",
      " 8   Chance of Admit    500 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 35.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='Serial No.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.iloc[:,0:-1]\n",
    "y = df.iloc[:,-1]\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>310</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>318</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>300</td>\n",
       "      <td>101</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>300</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>322</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>307</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>321</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>326</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>300</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "238        310          104                  3  2.0   3.5  8.37         0\n",
       "438        318          110                  1  2.5   3.5  8.54         1\n",
       "475        300          101                  3  3.5   2.5  7.88         0\n",
       "58         300           99                  1  3.0   2.0  6.80         1\n",
       "380        322          104                  3  3.5   4.0  8.84         1\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "255        307          110                  4  4.0   4.5  8.37         0\n",
       "72         321          111                  5  5.0   5.0  9.45         1\n",
       "396        325          107                  3  3.0   3.5  9.11         1\n",
       "235        326          111                  5  4.5   4.0  9.23         1\n",
       "37         300          105                  1  1.0   2.0  7.80         0\n",
       "\n",
       "[400 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scale = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scale.fit_transform(X_train)\n",
    "X_test_scaled = scale.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4       , 0.42857143, 0.5       , ..., 0.57142857, 0.50320513,\n",
       "        0.        ],\n",
       "       [0.56      , 0.64285714, 0.        , ..., 0.57142857, 0.55769231,\n",
       "        1.        ],\n",
       "       [0.2       , 0.32142857, 0.5       , ..., 0.28571429, 0.34615385,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.7       , 0.53571429, 0.5       , ..., 0.57142857, 0.74038462,\n",
       "        1.        ],\n",
       "       [0.72      , 0.67857143, 1.        , ..., 0.71428571, 0.77884615,\n",
       "        1.        ],\n",
       "       [0.2       , 0.46428571, 0.        , ..., 0.14285714, 0.32051282,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\uday.sharma\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\uday.sharma\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(7,activation='relu',input_dim = 7))\n",
    "model.add(Dense(7,activation='relu'))\n",
    "model.add(Dense(1,activation='linear')) # We are solving regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 8         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 120 (480.00 Byte)\n",
      "Trainable params: 120 (480.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\uday.sharma\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\uday.sharma\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "10/10 [==============================] - 1s 17ms/step - loss: 0.7459 - val_loss: 0.6807\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5494 - val_loss: 0.5027\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4132 - val_loss: 0.3762\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3146 - val_loss: 0.2872\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2393 - val_loss: 0.2181\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1784 - val_loss: 0.1601\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1291 - val_loss: 0.1151\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0907 - val_loss: 0.0806\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0618 - val_loss: 0.0561\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0415 - val_loss: 0.0396\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0295\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0191 - val_loss: 0.0242\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0227\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0154 - val_loss: 0.0216\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.0200\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0186\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0175\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0121 - val_loss: 0.0164\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.0154\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0109 - val_loss: 0.0145\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.0136\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0099 - val_loss: 0.0129\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0122\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0091 - val_loss: 0.0115\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0087 - val_loss: 0.0110\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0084 - val_loss: 0.0104\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0099\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0079 - val_loss: 0.0094\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0077 - val_loss: 0.0091\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0087\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0084\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0078\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0076\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0073\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0071\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0069\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0065 - val_loss: 0.0067\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0064 - val_loss: 0.0066\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0064\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0063\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0061 - val_loss: 0.0062\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0061 - val_loss: 0.0061\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0059\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0060 - val_loss: 0.0059\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0057\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0055\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0057 - val_loss: 0.0054\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0054\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0052\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0045\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0051 - val_loss: 0.0045\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0045\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0040\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train_scaled,y_train,validation_split=0.2,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 0s/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7051600450018799"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x24b1f1fab50>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
